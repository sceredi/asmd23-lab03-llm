# Testing llm's code generation capabilities

## Task 1

### ChatGPT
- Model: GPT 3.5
- Chat link: [testing chatgpt](https://chat.openai.com/share/77f4c146-886d-43cf-b9b9-127409313931)

I had to instruct it in order for it not to spit out some "random" code immediately and ask it nicely to wait for all the
interfaces definitions and it took quite a few tries in order to get it right. At some point it didn't want to work 
anymore and asked me to implement stuff, but simply asking it to do it for me was enough to maintain my lazyness
intact. After a few errors I had to ask if it wanted to see the test definition again and doing so helped quite a bit
with the following answers.

- Probably using GPT 4 would have helped
- Happy that I am faster than GPT 3.5 at not so trivial implementations
